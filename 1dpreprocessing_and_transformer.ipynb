{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":46105,"databundleVersionId":5087314,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## 0. Dataset Description\n*Taken from dataset [Kaggle page](https://www.kaggle.com/competitions/asl-signs/data)*\n\nDeaf children are often born to hearing parents who do not know sign language. Your challenge in this competition is to help identify signs made in processed videos, which will support the development of mobile apps to help teach parents sign language so they can communicate with their Deaf children.\n\n### 0.1. Files\n`train_landmark_files/[participant_id]/[sequence_id].parquet` \n\nThe landmark data. The landmarks were extracted from raw videos with the MediaPipe holistic model. Not all of the frames necessarily had visible hands or hands that could be detected by the model.\n\n- frame - The frame number in the raw video.\n- row_id - A unique identifier for the row.\n- type - The type of landmark. One of ['face', 'left_hand', 'pose', 'right_hand'].\n- landmark_index - The landmark index number. Details of the hand landmark locations can be found here.\n- [x/y/z] - The normalized spatial coordinates of the landmark. These are the only columns that will be provided to your submitted model for inference. The MediaPipe model is not fully trained to predict depth so you may wish to ignore the z values.\n\n`train.csv`\n- path - The path to the landmark file.\n- participant_id - A unique identifier for the data contributor.\n- sequence_id - A unique identifier for the landmark sequence.\n- sign - The label for the landmark sequence.","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup","metadata":{}},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:27:19.925740Z","iopub.execute_input":"2025-04-11T17:27:19.925936Z","iopub.status.idle":"2025-04-11T17:27:20.746304Z","shell.execute_reply.started":"2025-04-11T17:27:19.925915Z","shell.execute_reply":"2025-04-11T17:27:20.745328Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"BASE_DIR = \"../input/asl-signs/\"\n\n# Read in train dataset\n\ndf = pd.read_csv(f\"{BASE_DIR}/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:27:20.747162Z","iopub.execute_input":"2025-04-11T17:27:20.747473Z","iopub.status.idle":"2025-04-11T17:27:20.982860Z","shell.execute_reply.started":"2025-04-11T17:27:20.747454Z","shell.execute_reply":"2025-04-11T17:27:20.982119Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## 2. Dataset Information","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:27:20.983807Z","iopub.execute_input":"2025-04-11T17:27:20.984137Z","iopub.status.idle":"2025-04-11T17:27:21.010445Z","shell.execute_reply.started":"2025-04-11T17:27:20.984104Z","shell.execute_reply":"2025-04-11T17:27:21.009666Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                            path  participant_id  sequence_id  \\\n0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n\n    sign  \n0   blow  \n1   wait  \n2  cloud  \n3   bird  \n4   owie  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>participant_id</th>\n      <th>sequence_id</th>\n      <th>sign</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmark_files/26734/1000035562.parquet</td>\n      <td>26734</td>\n      <td>1000035562</td>\n      <td>blow</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmark_files/28656/1000106739.parquet</td>\n      <td>28656</td>\n      <td>1000106739</td>\n      <td>wait</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmark_files/16069/100015657.parquet</td>\n      <td>16069</td>\n      <td>100015657</td>\n      <td>cloud</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_landmark_files/25571/1000210073.parquet</td>\n      <td>25571</td>\n      <td>1000210073</td>\n      <td>bird</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_landmark_files/62590/1000240708.parquet</td>\n      <td>62590</td>\n      <td>1000240708</td>\n      <td>owie</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:27:21.012460Z","iopub.execute_input":"2025-04-11T17:27:21.012678Z","iopub.status.idle":"2025-04-11T17:27:21.017731Z","shell.execute_reply.started":"2025-04-11T17:27:21.012659Z","shell.execute_reply":"2025-04-11T17:27:21.016840Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(94477, 4)"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"`train.csv` has 4 features: the path to each parquet file, the corresponding participant's id, the sequence id, and the sign. Contains 94477 entries.","metadata":{}},{"cell_type":"code","source":"df[\"sign\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:27:21.019338Z","iopub.execute_input":"2025-04-11T17:27:21.019592Z","iopub.status.idle":"2025-04-11T17:27:21.051631Z","shell.execute_reply.started":"2025-04-11T17:27:21.019571Z","shell.execute_reply":"2025-04-11T17:27:21.050924Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"sign\nlisten    415\nlook      414\nshhh      411\ndonkey    410\nmouse     408\n         ... \ndance     312\nperson    312\nbeside    310\nvacuum    307\nzipper    299\nName: count, Length: 250, dtype: int64"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"top_k = 20 # How many signs to plot \nfig, ax = plt.subplots(figsize=(8, 8))\ndf[\"sign\"].value_counts().head(top_k).sort_values(ascending=True).plot(\n    kind=\"barh\", ax=ax, title=f\"Top {top_k} Signs in Training Dataset\"\n)\nax.set_xlabel(\"Number of Training Samples\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:27:21.052313Z","iopub.execute_input":"2025-04-11T17:27:21.052586Z","iopub.status.idle":"2025-04-11T17:27:21.626153Z","shell.execute_reply.started":"2025-04-11T17:27:21.052556Z","shell.execute_reply":"2025-04-11T17:27:21.625204Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x800 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8, 8))\ndf[\"sign\"].value_counts().tail(top_k).sort_values(ascending=True).plot(\n    kind=\"barh\", ax=ax, title=f\"Bottom {top_k} Signs in Training Dataset\"\n)\nax.set_xlabel(\"Number of Training Samples\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:27:21.626928Z","iopub.execute_input":"2025-04-11T17:27:21.627182Z","iopub.status.idle":"2025-04-11T17:27:21.909955Z","shell.execute_reply.started":"2025-04-11T17:27:21.627161Z","shell.execute_reply":"2025-04-11T17:27:21.908975Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x800 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"Recall that the Parquet files are stored in the `train_landmark_files` directory. Each entry in `train.csv` contains the path to a specific Parquet file.","metadata":{}},{"cell_type":"code","source":"# Get the path to a Parquet file that has the \"cow\" sign\ntarget_sign = \"cow\"\nexample_parquet_path = df.query(f\"sign == '{target_sign}'\")[\"path\"].values[0]\nexample_parquet_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:28:38.034169Z","iopub.execute_input":"2025-04-11T17:28:38.034563Z","iopub.status.idle":"2025-04-11T17:28:38.046994Z","shell.execute_reply.started":"2025-04-11T17:28:38.034536Z","shell.execute_reply":"2025-04-11T17:28:38.046031Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"'train_landmark_files/36257/1021205595.parquet'"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"We can load the parquet file into a `Dataframe` to get the landmark information.","metadata":{}},{"cell_type":"code","source":"landmark_df = pd.read_parquet(f\"{BASE_DIR}/{example_parquet_path}\")\nlandmark_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:28:39.489908Z","iopub.execute_input":"2025-04-11T17:28:39.490275Z","iopub.status.idle":"2025-04-11T17:28:39.517975Z","shell.execute_reply.started":"2025-04-11T17:28:39.490247Z","shell.execute_reply":"2025-04-11T17:28:39.517296Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   frame    row_id  type  landmark_index         x         y         z\n0      1  1-face-0  face               0  0.476809  0.456741 -0.042842\n1      1  1-face-1  face               1  0.469517  0.416260 -0.068233\n2      1  1-face-2  face               2  0.471521  0.429064 -0.038716\n3      1  1-face-3  face               3  0.453238  0.387312 -0.047121\n4      1  1-face-4  face               4  0.467671  0.406001 -0.071225","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame</th>\n      <th>row_id</th>\n      <th>type</th>\n      <th>landmark_index</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1-face-0</td>\n      <td>face</td>\n      <td>0</td>\n      <td>0.476809</td>\n      <td>0.456741</td>\n      <td>-0.042842</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1-face-1</td>\n      <td>face</td>\n      <td>1</td>\n      <td>0.469517</td>\n      <td>0.416260</td>\n      <td>-0.068233</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1-face-2</td>\n      <td>face</td>\n      <td>2</td>\n      <td>0.471521</td>\n      <td>0.429064</td>\n      <td>-0.038716</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1-face-3</td>\n      <td>face</td>\n      <td>3</td>\n      <td>0.453238</td>\n      <td>0.387312</td>\n      <td>-0.047121</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1-face-4</td>\n      <td>face</td>\n      <td>4</td>\n      <td>0.467671</td>\n      <td>0.406001</td>\n      <td>-0.071225</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"example_landmark = landmark_df\nunique_frames = example_landmark[\"frame\"].nunique()\nunique_types = example_landmark[\"type\"].nunique()\ntypes_in_video = example_landmark[\"type\"].unique()\nprint(\n    f\"The file has {unique_frames} unique frames and {unique_types} unique types: {types_in_video}\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:28:39.781497Z","iopub.execute_input":"2025-04-11T17:28:39.781766Z","iopub.status.idle":"2025-04-11T17:28:39.790145Z","shell.execute_reply.started":"2025-04-11T17:28:39.781742Z","shell.execute_reply":"2025-04-11T17:28:39.789326Z"}},"outputs":[{"name":"stdout","text":"The file has 48 unique frames and 4 unique types: ['face' 'left_hand' 'pose' 'right_hand']\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"landmark_df[\"frame\"].value_counts().sort_index()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:28:40.041987Z","iopub.execute_input":"2025-04-11T17:28:40.042229Z","iopub.status.idle":"2025-04-11T17:28:40.048910Z","shell.execute_reply.started":"2025-04-11T17:28:40.042208Z","shell.execute_reply":"2025-04-11T17:28:40.048096Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"frame\n1     543\n2     543\n3     543\n4     543\n5     543\n6     543\n7     543\n8     543\n9     543\n10    543\n11    543\n12    543\n13    543\n14    543\n15    543\n16    543\n17    543\n18    543\n19    543\n20    543\n21    543\n22    543\n23    543\n24    543\n25    543\n26    543\n27    543\n28    543\n29    543\n30    543\n31    543\n32    543\n33    543\n34    543\n35    543\n36    543\n37    543\n38    543\n39    543\n40    543\n41    543\n42    543\n43    543\n44    543\n45    543\n46    543\n47    543\n48    543\nName: count, dtype: int64"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"## 3. WIP - 1D CNN preprocessing","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport gc\nimport os\nimport torch.cuda.amp as amp\nfrom torch.utils.data import Dataset, DataLoader\nimport random\nfrom sklearn.model_selection import train_test_split\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:17:36.915675Z","iopub.execute_input":"2025-04-11T18:17:36.915993Z","iopub.status.idle":"2025-04-11T18:17:36.920275Z","shell.execute_reply.started":"2025-04-11T18:17:36.915969Z","shell.execute_reply":"2025-04-11T18:17:36.919532Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"import torch\n\nprint(\"CUDA Available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"Using device:\", torch.cuda.get_device_name(0))\nelse:\n    print(\"Using CPU\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:27:28.997517Z","iopub.execute_input":"2025-04-11T17:27:28.997881Z","iopub.status.idle":"2025-04-11T17:27:29.124845Z","shell.execute_reply.started":"2025-04-11T17:27:28.997862Z","shell.execute_reply":"2025-04-11T17:27:29.123961Z"}},"outputs":[{"name":"stdout","text":"CUDA Available: True\nUsing device: Tesla T4\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:28:46.127802Z","iopub.execute_input":"2025-04-11T17:28:46.128145Z","iopub.status.idle":"2025-04-11T17:28:46.132062Z","shell.execute_reply.started":"2025-04-11T17:28:46.128114Z","shell.execute_reply":"2025-04-11T17:28:46.131251Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def seed_everything(seed=42):\n    # Set PYTHONHASHSEED for reproducibility\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \n    # Set random seed for Python's random module\n    random.seed(seed)\n    \n    # Set random seed for numpy\n    np.random.seed(seed)\n    \n    # Set random seed for PyTorch (both CPU and GPU)\n    torch.manual_seed(seed)\n    \n    # For GPU support\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)  # for all devices (GPUs)\n    \n    # Ensure deterministic behavior for reproducibility\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:28:47.276073Z","iopub.execute_input":"2025-04-11T17:28:47.276517Z","iopub.status.idle":"2025-04-11T17:28:47.281006Z","shell.execute_reply.started":"2025-04-11T17:28:47.276481Z","shell.execute_reply":"2025-04-11T17:28:47.280161Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def get_pytorch_dataset(df, batch_size=64, max_len=384, transform=None, gcs=False):\n    \"\"\"\n    Creates a PyTorch DataLoader from a DataFrame.\n    \n    Args:\n        df (pd.DataFrame): DataFrame containing file paths and labels.\n        batch_size (int): Batch size for loading data.\n        transform (callable, optional): Optional transformation to apply on the data.\n        gcs (bool): Whether to read files from GCS (True) or local file system (False).\n    \n    Returns:\n        DataLoader: A DataLoader that can be used for training/testing.\n    \"\"\"\n    dataset = SignLanguageDataset(df=df, max_len=max_len, transform=transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    return dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:28:48.098864Z","iopub.execute_input":"2025-04-11T17:28:48.099354Z","iopub.status.idle":"2025-04-11T17:28:48.103763Z","shell.execute_reply.started":"2025-04-11T17:28:48.099320Z","shell.execute_reply":"2025-04-11T17:28:48.103018Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nROWS_PER_FRAME = 543\nMAX_LEN = 384\nCROP_LEN = MAX_LEN\nNUM_CLASSES  = 250\nPAD = -100.\nNOSE=[\n    1,2,98,327\n]\nLNOSE = [98]\nRNOSE = [327]\nLIP = [ 0, \n    61, 185, 40, 39, 37, 267, 269, 270, 409,\n    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n]\nLLIP = [84,181,91,146,61,185,40,39,37,87,178,88,95,78,191,80,81,82]\nRLIP = [314,405,321,375,291,409,270,269,267,317,402,318,324,308,415,310,311,312]\n\nPOSE = [500, 502, 504, 501, 503, 505, 512, 513]\nLPOSE = [513,505,503,501]\nRPOSE = [512,504,502,500]\n\nREYE = [\n    33, 7, 163, 144, 145, 153, 154, 155, 133,\n    246, 161, 160, 159, 158, 157, 173,\n]\nLEYE = [\n    263, 249, 390, 373, 374, 380, 381, 382, 362,\n    466, 388, 387, 386, 385, 384, 398,\n]\n\nLHAND = np.arange(468, 489).tolist()\nRHAND = np.arange(522, 543).tolist()\n\nPOINT_LANDMARKS = LIP + LHAND + RHAND + NOSE + REYE + LEYE #+POSE\n\nNUM_NODES = len(POINT_LANDMARKS)\nCHANNELS = 6*NUM_NODES\n\nprint(NUM_NODES)\nprint(CHANNELS)\n\ndef interp1d_(x, target_len, method='random'):\n    \"\"\"Interpolates the input tensor to a target length.\"\"\"\n    length = x.shape[1]\n    target_len = max(1, target_len)\n    \n    if method == 'random':\n        # Randomly choose one of the interpolation methods\n        rand_val = torch.rand(())\n        if rand_val < 0.33:\n            method = 'bilinear'\n        else:\n            method = 'bicubic' if torch.rand(()) < 0.5 else 'nearest'\n    \n    # Resize the tensor using the chosen method\n    x = F.interpolate(x, size=(target_len, x.shape[2]), mode=method, align_corners=False)\n    return x\n\ndef torch_nan_mean(x, dim=0, keepdim=False):\n    \"\"\"Calculates mean, ignoring NaNs.\"\"\"\n    mask = ~torch.isnan(x)\n    x = torch.where(mask, x, torch.zeros_like(x))\n    count = mask.sum(dim=dim, keepdim=keepdim).clamp(min=1)  # Avoid division by zero\n    return x.sum(dim=dim, keepdim=keepdim) / count\n\ndef torch_nan_std(x, center=None, dim=0, keepdim=False):\n    \"\"\"Calculates standard deviation, ignoring NaNs.\"\"\"\n    if center is None:\n        center = torch_nan_mean(x, dim=dim, keepdim=True)\n    d = x - center\n    variance = torch_nan_mean(d * d, dim=dim, keepdim=keepdim)\n    return torch.sqrt(variance)\n\nclass Preprocess(nn.Module):\n    def __init__(self, max_len=None, point_landmarks=None):\n        super(Preprocess, self).__init__()\n        self.max_len = max_len\n        self.point_landmarks = point_landmarks\n\n    def forward(self, inputs):\n        # Ensure input is 4D (batch, time, points, channels)\n        if inputs.dim() == 3:\n            x = inputs.unsqueeze(0)\n        else:\n            x = inputs\n\n        # Calculate mean over landmarks (axis 2)\n        mean = torch_nan_mean(x[:, :, [17], :], dim=(1, 2), keepdim=True)\n        mean = torch.where(torch.isnan(mean), torch.tensor(0.5, dtype=x.dtype, device=x.device), mean)\n\n        # Gather the specified landmarks and calculate the standard deviation\n        x = x[:, :, self.point_landmarks, :]  # N, T, P, C\n        std = torch_nan_std(x, mean, dim=(1, 2), keepdim=True)\n\n        # Normalize the data\n        x = (x - mean) / std\n\n        # Trim the sequence to max_len if specified\n        if self.max_len is not None:\n            x = x[:, :self.max_len]\n        length = x.shape[1]\n\n        # Keep only the first two coordinates\n        x = x[..., :2]\n\n        # Compute first and second differences\n        if x.shape[1] > 1:\n            dx = torch.cat([x[:, 1:] - x[:, :-1], torch.zeros_like(x[:, :1])], dim=1)\n        else:\n            dx = torch.zeros_like(x)\n\n        if x.shape[1] > 2:\n            dx2 = torch.cat([x[:, 2:] - x[:, :-2], torch.zeros_like(x[:, :2])], dim=1)\n        else:\n            dx2 = torch.zeros_like(x)\n\n        # Concatenate the features\n        x = torch.cat([\n            x.reshape(-1, length, 2 * len(self.point_landmarks)),\n            dx.reshape(-1, length, 2 * len(self.point_landmarks)),\n            dx2.reshape(-1, length, 2 * len(self.point_landmarks)),\n        ], dim=-1)\n\n        # Replace NaNs with zeros\n        x = torch.where(torch.isnan(x), torch.tensor(0., dtype=x.dtype, device=x.device), x)\n\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:28:48.993162Z","iopub.execute_input":"2025-04-11T17:28:48.993462Z","iopub.status.idle":"2025-04-11T17:28:49.010799Z","shell.execute_reply.started":"2025-04-11T17:28:48.993438Z","shell.execute_reply":"2025-04-11T17:28:49.009899Z"}},"outputs":[{"name":"stdout","text":"118\n708\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Helper function to replace NaNs with zeroes\ndef torch_nanmean(x, dim=0, keepdim=False):\n    mask = ~torch.isnan(x)\n    x = torch.where(mask, x, torch.zeros_like(x))\n    count = mask.sum(dim=dim, keepdim=keepdim).clamp(min=1)  # Avoid division by zero\n    return x.sum(dim=dim, keepdim=keepdim) / count\n\n# Decode TFRecord equivalent\ndef decode_torchrec(record_bytes):\n    coordinates = record_bytes['coordinates']\n    sign = record_bytes['sign']\n    out = {\n        'coordinates': coordinates.view(-1, ROWS_PER_FRAME, 3),\n        'sign': sign\n    }\n    return out\n\n# Filter NaNs\ndef filter_nans_torch(x, ref_point=POINT_LANDMARKS):\n    # Convert to tensor if input is a NumPy array\n    if isinstance(x, np.ndarray):\n        x = torch.tensor(x, dtype=torch.float32)\n        \n    # Check for NaNs across rows (axis=1) and keep rows that are not all NaN\n    mask = ~torch.all(torch.isnan(x), dim=1)\n    return x[mask]\n\n# Create a label-to-index mapping (only once)\nsign_to_index = {sign: idx for idx, sign in enumerate(df['sign'].unique())}\n\ndef preprocess(x, sign, augment=True, max_len=MAX_LEN):\n    coord = torch.as_tensor(x, dtype=torch.float32)\n\n    # Replace NaNs with PAD value\n    coord = filter_nans_torch(coord)\n\n    # Ensure proper shape: (T, 543, 3)\n    total_points = coord.size(0)\n    expected_size = ROWS_PER_FRAME * 3\n\n    if total_points % expected_size != 0:\n        padding_needed = expected_size - (total_points % expected_size)\n        if padding_needed < expected_size:\n            pad = torch.full((padding_needed, coord.size(1)), PAD, dtype=torch.float32)\n            coord = torch.cat((coord, pad), dim=0)\n        else:\n            coord = coord[:total_points - (total_points % expected_size)]\n\n    coord = coord.view(-1, ROWS_PER_FRAME, 3)\n\n    # print(\"Before flip\", coord.shape)\n\n    # # Apply flip here\n    # coord = coord[:, POINT_LANDMARKS, :]\n\n    # print(\"After flip\", coord.shape)\n\n\n    # Apply augmentation\n    if augment:\n        coord = augment_fn(coord, max_len=max_len)\n\n    # Apply padding of zeros\n    if coord.shape[0] < max_len:\n        pad_len = max_len - coord.shape[0]\n        pad = torch.zeros((pad_len, coord.shape[1], coord.shape[2]))\n        coord = torch.cat([coord, pad], dim=0)\n    else:\n        coord = coord[:max_len]\n\n    # print(\"After padding\", coord.shape)\n\n\n    # Run through preprocessing module\n    preprocessor = Preprocess(max_len=max_len, point_landmarks=POINT_LANDMARKS)\n    processed = preprocessor(coord.unsqueeze(0)).squeeze(0)  # Output: (max_len, CHANNELS)\n\n    # Convert sign to one-hot label\n    sign_index = sign_to_index[sign]\n    one_hot_label = F.one_hot(torch.tensor(sign_index), NUM_CLASSES)\n\n    return processed.float(), one_hot_label\n\n\n# def preprocess(x, sign, augment=False, max_len=MAX_LEN):\n#     coord = torch.as_tensor(x, dtype=torch.float32)\n#     coord = filter_nans_torch(x)\n\n#     # Check if the size is divisible by the expected number of columns (543 * 3)\n#     total_points = coord.size(0)\n#     expected_size = ROWS_PER_FRAME * 3\n\n#     # Padding or truncation if necessary\n#     if total_points % expected_size != 0:\n#         padding_needed = expected_size - (total_points % expected_size)\n#         if padding_needed < expected_size:\n#             pad = torch.zeros((padding_needed, coord.size(1)), dtype=torch.float32)\n    #         coord = torch.cat((coord, pad), dim=0)\n    #     else:\n    #         coord = coord[:total_points - (total_points % expected_size)]\n\n    # # Reshape the coordinates to (-1, ROWS_PER_FRAME, 3)\n    # coord = coord.view(-1, ROWS_PER_FRAME, 3)\n\n    # # Augmentation if required\n    # if augment:\n    #     coord = augment_fn(coord, max_len=max_len)\n\n    # # Convert sign to an integer label using the mapping\n    # sign_index = sign_to_index[sign]\n\n    # return coord.float(), F.one_hot(torch.tensor(sign_index), NUM_CLASSES)\n\n# def preprocess(x, augment=False, max_len=MAX_LEN):\n#     coord = x['coordinates']\n    \n#     # Filter out NaNs (assuming the function is implemented in PyTorch)\n    # # coord = filter_nans(coord)\n    \n    # # # Apply augmentation if specified\n    # # if augment:\n    # #     coord = augment_fn(coord, max_len=max_len)\n    \n    # # # Ensure the shape (this can be done with padding or truncation if necessary)\n    # # coord = coord.view(-1, ROWS_PER_FRAME, 3)  # Reshape the tensor\n    \n    # # # Apply the Preprocess transformation (assuming it's implemented for PyTorch)\n    # # coord = Preprocess(max_len=max_len)(coord)[0]  # Get the first element if it's a tuple\n    \n    # # # Convert to float32\n    # # coord = coord.float()\n    \n    # # # Convert the sign to a one-hot encoded tensor\n    # # sign = torch.tensor(x['sign'], dtype=torch.long)\n    # # target = torch.nn.functional.one_hot(sign, num_classes=NUM_CLASSES).float()\n    \n    # # return coord, target\n\n# Flip left-right\ndef flip_lr(x):\n    x[..., 0] = 1 - x[..., 0]\n    new_x = x.clone()\n\n    # Swap landmarks based on constants\n    for l, r in zip([LHAND, LLIP, LPOSE, LEYE, LNOSE], [RHAND, RLIP, RPOSE, REYE, RNOSE]):\n        new_x[l], new_x[r] = x[r], x[l]\n\n    return new_x\n\n# Temporal resampling\ndef resample(x, rate=(0.8, 1.2)):\n    rate = torch.FloatTensor(1).uniform_(*rate).item()\n    length = x.shape[0]\n    new_size = int(rate * length)\n    return F.interpolate(x.unsqueeze(0), size=(new_size, x.shape[1]), mode='bilinear', align_corners=False).squeeze(0)\n\n# Spatial random affine transformation, applies randomized scaling, shearing, rotation, and shifting to 2D coordinates\ndef spatial_random_affine(xyz, scale=(0.8, 1.2), shear=(-0.15, 0.15), shift=(-0.1, 0.1), degree=(-30, 30)):\n    center = torch.tensor([0.5, 0.5], dtype=torch.float32)\n\n    if scale:\n        scale_factor = torch.FloatTensor(1).uniform_(*scale).item()\n        xyz *= scale_factor\n\n    if shear:\n        shear_x = shear_y = torch.FloatTensor(1).uniform_(*shear).item()\n        if torch.rand(1).item() < 0.5:\n            shear_x = 0.0\n        else:\n            shear_y = 0.0\n        shear_mat = torch.tensor([[1., shear_x], [shear_y, 1.]], dtype=torch.float32)\n        xy = torch.matmul(xyz[..., :2], shear_mat)\n        xyz[..., :2] = xy\n\n    if degree:\n        deg = torch.FloatTensor(1).uniform_(*degree).item()\n        rad = torch.tensor(deg / 180 * np.pi)\n        c, s = torch.cos(rad), torch.sin(rad)\n        rotate_mat = torch.tensor([[c, s], [-s, c]], dtype=torch.float32)\n        xy = xyz[..., :2] - center\n        xy = torch.matmul(xy, rotate_mat) + center\n        xyz[..., :2] = xy\n\n    if shift:\n        shift_val = torch.FloatTensor(1).uniform_(*shift).item()\n        xyz += shift_val\n\n    return xyz\n\n# Temporal crop, cuts out random parts of sequence\ndef temporal_crop(x, length=MAX_LEN):\n    l = x.shape[0]\n    offset = torch.randint(0, max(1, l - length + 1), (1,)).item()\n    return x[offset:offset + length]\n\n# Temporal mask, masks a continuous chunk of frames over *time*.\ndef temporal_mask(x, size=(0.2, 0.4), mask_value=0.0):\n    l = x.shape[0]\n    mask_size = int(torch.FloatTensor(1).uniform_(*size).item() * l)\n    mask_offset = torch.randint(0, max(1, l - mask_size + 1), (1,)).item()\n    x[mask_offset:mask_offset + mask_size] = mask_value\n    return x\n\n# Spatial mask, masks a rectangular spatial *region* within the (x, y) coordinates of the input.\n# Like hiding a hand or body part\ndef spatial_mask(x, size=(0.2, 0.4), mask_value=0.0):\n    mask_size = torch.FloatTensor(1).uniform_(*size).item()\n    mask_offset_y = torch.rand(1).item()\n    mask_offset_x = torch.rand(1).item()\n    y_mask = (x[..., 1] > mask_offset_y) & (x[..., 1] < mask_offset_y + mask_size)\n    x_mask = (x[..., 0] > mask_offset_x) & (x[..., 0] < mask_offset_x + mask_size)\n    mask = y_mask & x_mask\n    x[mask] = mask_value\n    return x\n\ndef augment_fn(x, always=False, max_len=None):\n    # if random.random() < 0.5 or always:\n    #     x = flip_lr(x)\n    #     print(\"flip applied\")\n    # if random.random() < 0.8 or always:\n    #     x = resample(x, (0.5, 1.5))\n    #     print(\"resample applied\", x.shape)\n    if max_len is not None:\n        x = temporal_crop(x, max_len)\n        # print(\"temporal crop applied\", x.shape)\n    if random.random() < 0.75 or always:\n        x = spatial_random_affine(x)\n        # print(\"spatial random affine applied\", x.shape)\n    if random.random() < 0.5 or always:\n        x = temporal_mask(x)\n        # print(\"temporal mask applied\", x.shape)\n    if random.random() < 0.5 or always:\n        x = spatial_mask(x)\n        # print(\"spatial mask applied\", x.shape)\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T17:28:49.741169Z","iopub.execute_input":"2025-04-11T17:28:49.741466Z","iopub.status.idle":"2025-04-11T17:28:49.766123Z","shell.execute_reply.started":"2025-04-11T17:28:49.741443Z","shell.execute_reply":"2025-04-11T17:28:49.765417Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pyarrow.parquet as pq\n\nclass SignLanguageDataset(Dataset):\n    def __init__(self, df, max_len, transform=None):\n        self.data = df\n        self.max_len = max_len\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # Get the sample from the DataFrame\n        sample = self.data.iloc[idx]\n\n        # Load the Parquet file specified in the 'path' column\n        path = f\"{BASE_DIR}/{sample['path']}\"\n        landmark_df = pd.read_parquet(path)\n\n        # Extract coordinates (x, y, z) from the DataFrame\n        coordinates = landmark_df[['x', 'y', 'z']].values\n\n        sign = sample['sign']\n\n        # Preprocess the data\n        if self.transform:\n            # coordinates = self.transform(coordinates, sign)\n            coordinates, sign = self.transform(coordinates, sign)\n        else:\n            coordinates = landmark_df[['x', 'y', 'z']].fillna(0).values\n            coordinates = np.asarray(coordinates, dtype=np.float32)\n    \n            # Pad/truncate to max_len\n            if coordinates.shape[0] > self.max_len:\n                coordinates = coordinates[:self.max_len]\n            elif coordinates.shape[0] < self.max_len:\n                pad_len = self.max_len - coordinates.shape[0]\n                padding = np.zeros((pad_len, 3), dtype=np.float32)\n                coordinates = np.vstack((coordinates, padding))\n\n        # Convert the sign to a numeric label if necessary\n        # Assuming you have a label-to-index mapping\n        sign = sample['sign']\n        if isinstance(sign, str):\n            sign = sign_to_index[sign]\n\n        # coordinates = landmark_df[['x', 'y', 'z']].fillna(0).values\n        # coordinates = np.asarray(coordinates, dtype=np.float32)\n        \n        # # Pad/truncate to max_len\n        # if coordinates.shape[0] > self.max_len:\n        #     coordinates = coordinates[:self.max_len]\n        # elif coordinates.shape[0] < self.max_len:\n        #     pad_len = self.max_len - coordinates.shape[0]\n        #     padding = np.zeros((pad_len, 3), dtype=np.float32)\n        #     coordinates = np.vstack((coordinates, padding))\n        inputs = torch.tensor(coordinates, dtype=torch.float32)\n\n        # Transposed to fit dimensions\n        # inputs = inputs.transpose(0, 1)\n        target = torch.tensor(sign, dtype=torch.long)\n        return inputs, target\n\n# Example usage!!\ndataset = SignLanguageDataset(df=df, max_len=64, transform=preprocess)\ndata_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n\nfor inputs, targets in data_loader:\n    print(inputs.shape, targets.shape)\n    print(inputs)\n    print(\"AAAA\")\n    print(targets)\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:16:07.415674Z","iopub.execute_input":"2025-04-11T18:16:07.416005Z","iopub.status.idle":"2025-04-11T18:16:09.655144Z","shell.execute_reply.started":"2025-04-11T18:16:07.415979Z","shell.execute_reply":"2025-04-11T18:16:09.654150Z"}},"outputs":[{"name":"stdout","text":"torch.Size([64, 384, 708]) torch.Size([64])\ntensor([[[-0.0143, -0.0136, -0.0143,  ...,  0.0000,  0.0000,  0.0000],\n         [-0.0143, -0.0136, -0.0143,  ...,  0.0000,  0.0000,  0.0000],\n         [-0.0143, -0.0136, -0.0143,  ...,  0.0000,  0.0000,  0.0000],\n         ...,\n         [-0.0143, -0.0136, -0.0143,  ...,  0.0000,  0.0000,  0.0000],\n         [-0.0143, -0.0136, -0.0143,  ...,  0.0000,  0.0000,  0.0000],\n         [-0.0143, -0.0136, -0.0143,  ...,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.1086,  0.1201,  0.1030,  ...,  0.0140, -0.0015,  0.0099],\n         [ 0.0896,  0.1020,  0.1073,  ..., -0.0134, -0.0433,  0.1221],\n         [ 0.1045,  0.1237,  0.0918,  ..., -0.0186, -0.0116, -0.0034],\n         ...,\n         [ 0.0617,  0.0613,  0.0617,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0617,  0.0613,  0.0617,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0617,  0.0613,  0.0617,  ...,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.0970,  0.1287,  0.0844,  ...,  0.0171,  0.0051,  0.0101],\n         [ 0.0575,  0.1130,  0.0937,  ..., -0.0357,  0.0033,  0.0109],\n         [ 0.0888,  0.1374,  0.0649,  ...,  0.0390,  0.0303,  0.0041],\n         ...,\n         [ 0.0342,  0.0274,  0.0342,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0342,  0.0274,  0.0342,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0342,  0.0274,  0.0342,  ...,  0.0000,  0.0000,  0.0000]],\n\n        ...,\n\n        [[ 0.1386,  0.0676,  0.1233,  ...,  0.0155, -0.0098,  0.0087],\n         [ 0.1121,  0.0422,  0.1340,  ..., -0.0135, -0.0021,  0.0077],\n         [ 0.1283,  0.0683,  0.1211,  ..., -0.0074, -0.1552,  0.0778],\n         ...,\n         [-0.0108, -0.0047, -0.0108,  ...,  0.0000,  0.0000,  0.0000],\n         [-0.0108, -0.0047, -0.0108,  ...,  0.0000,  0.0000,  0.0000],\n         [-0.0108, -0.0047, -0.0108,  ...,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.1208,  0.0912,  0.1145,  ...,  0.0116, -0.0074,  0.0073],\n         [ 0.0994,  0.0679,  0.1179,  ..., -0.0152, -0.0022,  0.0057],\n         [ 0.1150,  0.0913,  0.1015,  ...,  0.0360, -0.0052,  0.0007],\n         ...,\n         [ 0.0584,  0.0600,  0.0584,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0584,  0.0600,  0.0584,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0584,  0.0600,  0.0584,  ...,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.0990,  0.0937,  0.0914,  ...,  0.0117, -0.0052,  0.0057],\n         [ 0.0818,  0.0747,  0.0976,  ..., -0.0126, -0.0784,  0.0957],\n         [ 0.0948,  0.0950,  0.0857,  ..., -0.0197, -0.0117, -0.0056],\n         ...,\n         [ 0.0305,  0.0318,  0.0305,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0305,  0.0318,  0.0305,  ...,  0.0000,  0.0000,  0.0000],\n         [ 0.0305,  0.0318,  0.0305,  ...,  0.0000,  0.0000,  0.0000]]])\nAAAA\ntensor([153, 243, 118,  47, 187,  90, 214, 183, 214,  41, 218,  12, 183, 221,\n        226, 228,  43, 151, 220,  30, 234, 217, 205, 119, 133, 147,  52, 153,\n        235,  75, 139, 187,  13, 116, 159,  68,  83, 115,  93, 131, 190, 132,\n        127, 232, 142, 241, 176, 246,  19, 177, 224,  34, 151, 143,  91, 198,\n        188,  75, 157, 115,  65,  59, 243, 200])\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"## Transformer model","metadata":{}},{"cell_type":"code","source":"class MultiHeadSelfAttention(nn.Module):\n    def __init__(self, dim=256, num_heads=4, dropout=0):\n        super().__init__()\n        self.dim = dim\n        self.scale = dim ** -0.5\n        self.num_heads = num_heads\n        self.qkv = nn.Linear(dim, 3 * dim, bias=False)\n        self.drop1 = nn.Dropout(dropout)\n        self.proj = nn.Linear(dim, dim, bias=False)\n\n    def forward(self, x, mask=None):\n        batch_size, seq_len, _ = x.shape\n        qkv = self.qkv(x).reshape(batch_size, seq_len, 3, self.num_heads, self.dim // self.num_heads)\n        q, k, v = qkv.unbind(dim=2)\n\n        attn = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n        if mask is not None:\n            attn = attn.masked_fill(mask[:, None, None, :].bool(), float('-inf'))\n        attn = F.softmax(attn, dim=-1)\n        attn = self.drop1(attn)\n\n        x = torch.matmul(attn, v).transpose(1, 2).reshape(batch_size, seq_len, self.dim)\n        x = self.proj(x)\n        return x\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, dim=256, num_heads=4, expand=4, attn_dropout=0.2, drop_rate=0.2, activation=nn.SiLU()):\n        super().__init__()\n        self.attn_norm = nn.BatchNorm1d(dim)\n        self.attn = MultiHeadSelfAttention(dim=dim, num_heads=num_heads, dropout=attn_dropout)\n        self.attn_drop = nn.Dropout(drop_rate)\n        self.ffn_norm = nn.BatchNorm1d(dim)\n        self.ffn = nn.Sequential(\n            nn.Linear(dim, dim * expand, bias=False),\n            activation,\n            nn.Linear(dim * expand, dim, bias=False),\n            nn.Dropout(drop_rate)\n        )\n\n    def forward(self, x):\n        attn_out = x + self.attn_drop(self.attn(self.attn_norm(x.transpose(1, 2)).transpose(1, 2)))\n        x = attn_out + self.ffn(self.ffn_norm(attn_out.transpose(1, 2)).transpose(1, 2))\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:12:34.847169Z","iopub.execute_input":"2025-04-11T18:12:34.847510Z","iopub.status.idle":"2025-04-11T18:12:34.856544Z","shell.execute_reply.started":"2025-04-11T18:12:34.847475Z","shell.execute_reply":"2025-04-11T18:12:34.855756Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"class GetModel(nn.Module):\n    def __init__(self, max_len=64, dropout_step=0, dim=192, channels=CHANNELS, num_classes=NUM_CLASSES):\n        super(GetModel, self).__init__()\n        self.max_len = max_len\n        self.channels = channels\n        self.dim = dim\n        self.num_classes = num_classes\n        self.ksize = 17\n\n        # Stem\n        self.stem_conv = nn.Linear(channels, dim, bias=False)\n        self.stem_bn = nn.BatchNorm1d(max_len, momentum=0.95)\n\n        # Blocks\n        self.blocks = nn.Sequential(\n            Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n            Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n            Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n            TransformerBlock(dim, expand=2),\n            Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n            Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n            Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n            TransformerBlock(dim, expand=2)\n        )\n\n        # Additional blocks for the 4x model\n        if dim == 384:\n            self.extra_blocks = nn.Sequential(\n                Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n                Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n                Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n                TransformerBlock(dim, expand=2),\n                Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n                Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n                Conv1DBlock(dim, self.ksize, drop_rate=0.2),\n                TransformerBlock(dim, expand=2)\n            )\n        else:\n            self.extra_blocks = None\n\n        # Top layers\n        self.top_conv = nn.Linear(dim, dim * 2)\n        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n        self.dropout = nn.Dropout(0.8)\n        self.classifier = nn.Linear(dim * 2, num_classes)\n\n    def forward(self, x):\n        x = self.stem_conv(x)\n        x = self.stem_bn(x)\n        x = self.blocks(x)\n\n        if self.extra_blocks:\n            x = self.extra_blocks(x)\n\n        x = self.top_conv(x)\n        x = self.global_avg_pool(x).squeeze(-1)\n        x = self.dropout(x)\n        x = self.classifier(x)\n        return x\n\n# Instantiate model\n# model = GetModel()\n\n# Example forward pass\n# temp_train should be a list of inputs, where temp_train[0] is input data and temp_train[1] is the labels\n# y = model(torch.tensor(temp_train[0]))\n# loss = nn.CrossEntropyLoss()(y, torch.tensor(temp_train[1]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T18:12:34.857788Z","iopub.execute_input":"2025-04-11T18:12:34.858012Z","iopub.status.idle":"2025-04-11T18:12:34.892370Z","shell.execute_reply.started":"2025-04-11T18:12:34.857992Z","shell.execute_reply":"2025-04-11T18:12:34.891758Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom torch.cuda.amp import GradScaler, autocast\nfrom sklearn.metrics import accuracy_score\n\n# Training function\ndef train_fold(CFG, fold, train_files, valid_files=None, strategy=None, summary=True):\n    seed_everything(CFG.seed)\n    gc.collect()\n\n    # Set mixed precision\n    if CFG.fp16:\n        scaler = GradScaler()  # Updated to use GradScaler directly \n    else:\n        scaler = None\n        \n    df = CFG.df\n    if fold != 'all':\n        train_df = df[df['path'].isin(train_files)].reset_index(drop=True)\n        valid_df = df[df['path'].isin(valid_files)].reset_index(drop=True)\n        train_ds = get_pytorch_dataset(train_df, CFG.batch_size, CFG.max_len, transform=preprocess)\n        valid_ds = get_pytorch_dataset(valid_df, CFG.batch_size, CFG.max_len)\n    else:\n        train_df = df[df['path'].isin(train_files)].reset_index(drop=True)\n        train_ds = get_pytorch_dataset(train_df, CFG.batch_size, CFG.max_len, transform=preprocess)\n        valid_ds = None\n        valid_files = []\n\n    num_train = len(train_df)  # Use the actual number of samples, not dataset length\n    num_valid = len(valid_df) if valid_ds is not None else 0\n    \n    # Calculate actual steps per epoch correctly\n    steps_per_epoch = (num_train + CFG.batch_size - 1) // CFG.batch_size  # Ceiling division\n    print(f\"Number of training samples: {num_train}, batches: {steps_per_epoch}\")\n    print(f\"Number of validation samples: {num_valid}\")\n    \n    dropout_step = CFG.dropout_start_epoch * steps_per_epoch\n\n    model = GetModel(dim=CFG.dim, max_len=CFG.max_len, dropout_step=CFG.dropout_start_epoch)\n    model = model.to(CFG.device)\n\n    # Optimizer and scheduler\n    optimizer = optim.AdamW(model.parameters(), lr=CFG.lr)\n    \n    # Calculate total steps correctly for OneCycleLR\n    total_steps = steps_per_epoch * CFG.epoch\n    scheduler = optim.lr_scheduler.OneCycleLR(\n        optimizer, \n        max_lr=CFG.lr, \n        total_steps=total_steps,\n        pct_start=CFG.warmup\n    )\n\n    # Loss function\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\n    if summary:\n        print(f\"Training fold {fold}...\")\n        print(model)\n        print(f\"Total training steps: {total_steps}\")\n\n    # Checkpoint for saving best model\n    best_val_loss = float('inf')\n    best_val_acc = 0.0\n    \n    # Training loop\n    for epoch in range(CFG.resume, CFG.epoch):\n        start_time = time.time()\n        print(\"On epoch number:\", epoch + 1, \"/\", CFG.epoch)\n        model.train()\n        running_loss = 0.0\n        all_preds = []\n        all_targets = []\n        \n        for step, (inputs, targets) in enumerate(train_ds):\n            inputs, targets = inputs.to(CFG.device), targets.to(CFG.device)\n            optimizer.zero_grad()\n            \n            with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n                outputs = model(inputs)\n                print(outputs.shape)\n                loss = criterion(outputs, targets)\n            \n            if scaler:\n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                loss.backward()\n                optimizer.step()\n\n            running_loss += loss.item()\n            \n            # Calculate accuracy \n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n            \n            # Scheduler step\n            scheduler.step()\n\n        # Calculate training metrics\n        time_end = time.time()\n        print(f\"Epoch {epoch+1} took {time_end - start_time} seconds to train\")\n        epoch_loss = running_loss / len(train_ds)\n        epoch_acc = accuracy_score(all_targets, all_preds)\n        print(f\"Epoch {epoch+1}/{CFG.epoch}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n\n        # Validation step\n        if valid_ds is not None:\n            model.eval()\n            val_loss = 0.0\n            val_preds = []\n            val_targets = []\n            \n            with torch.no_grad():\n                for inputs, targets in valid_ds:\n                    inputs, targets = inputs.to(CFG.device), targets.to(CFG.device)\n                    outputs = model(inputs)\n                    loss = criterion(outputs, targets)\n                    val_loss += loss.item()\n                    \n                    # Calculate validation accuracy\n                    _, preds = torch.max(outputs, 1)\n                    val_preds.extend(preds.cpu().numpy())\n                    val_targets.extend(targets.cpu().numpy())\n                    \n            val_loss /= len(valid_ds)\n            val_acc = accuracy_score(val_targets, val_preds)\n            print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n            \n            # Save best model based on validation loss\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                torch.save(model.state_dict(), f\"{CFG.output_dir}/{CFG.comment}-fold{fold}-best-loss.pth\")\n                \n            # Save best model based on validation accuracy\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                torch.save(model.state_dict(), f\"{CFG.output_dir}/{CFG.comment}-fold{fold}-best-acc.pth\")\n        \n        # Save model checkpoint periodically\n        if (epoch + 1) % 10 == 0:\n            torch.save(model.state_dict(), f\"{CFG.output_dir}/{CFG.comment}-fold{fold}-epoch{epoch+1}.pth\")\n    \n    # Load best model for evaluation\n    model.load_state_dict(torch.load(f\"{CFG.output_dir}/{CFG.comment}-fold{fold}-best-loss.pth\"))\n    \n    # Final evaluation\n    if valid_ds is not None:\n        model.eval()\n        val_loss = 0.0\n        val_preds = []\n        val_targets = []\n        \n        with torch.no_grad():\n            for inputs, targets in valid_ds:\n                inputs, targets = inputs.to(CFG.device), targets.to(CFG.device)\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                val_loss += loss.item()\n                \n                # Calculate final accuracy\n                _, preds = torch.max(outputs, 1)\n                val_preds.extend(preds.cpu().numpy())\n                val_targets.extend(targets.cpu().numpy())\n                \n        val_loss /= len(valid_ds)\n        val_acc = accuracy_score(val_targets, val_preds)\n        print(f\"Final Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n\n    if valid_ds is not None:\n        return model, val_loss, val_acc\n    else:\n        return model, None, None\n\n# Training loop for multiple folds\ndef train_folds(CFG, folds, strategy=None, summary=True):\n    results = []\n    for fold in folds:\n        if fold != 'all':\n            all_files = CFG.df[\"path\"].tolist()  # Fixed to use CFG.df\n            train_files, valid_files = train_test_split(all_files, test_size=0.2, random_state=CFG.seed, shuffle=True)\n        else:\n            train_files = CFG.df[\"path\"]  # Fixed to use CFG.df\n            valid_files = None\n\n        model, val_loss, val_acc = train_fold(CFG, fold, train_files, valid_files, strategy=strategy, summary=summary)\n        results.append((fold, val_loss, val_acc))\n    \n    # Print summary of results\n    print(\"\\nTraining Results Summary:\")\n    for fold, loss, acc in results:\n        if acc is not None:\n            print(f\"Fold {fold}: Loss = {loss:.4f}, Accuracy = {acc:.4f}\")\n        else:\n            print(f\"Fold {fold}: Loss = {loss:.4f}\")\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T19:28:51.665849Z","iopub.execute_input":"2025-04-11T19:28:51.666188Z","iopub.status.idle":"2025-04-11T19:28:51.684421Z","shell.execute_reply.started":"2025-04-11T19:28:51.666162Z","shell.execute_reply":"2025-04-11T19:28:51.683507Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"# Efficient Channel Attention (ECA) Layer\nclass ECA(nn.Module):\n    def __init__(self, kernel_size=5):\n        super().__init__()\n        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n        self.conv = nn.Conv1d(1, 1, kernel_size=kernel_size, \n                             padding=(kernel_size - 1) // 2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        # x is [B, C, L]\n        # Take channel attention\n        y = self.avg_pool(x)  # [B, C, 1]\n        \n        # Transpose to use conv1d across channels\n        y = y.transpose(1, 2)  # [B, 1, C]\n        y = self.conv(y)\n        y = self.sigmoid(y)\n        y = y.transpose(1, 2)  # [B, C, 1]\n        \n        # Multiply with input\n        return x * y\n\n# LateDropout Layer\nclass LateDropout(nn.Module):\n    def __init__(self, rate, start_step=0):\n        super().__init__()\n        self.rate = rate\n        self.start_step = start_step\n        self.train_counter = 0\n        self.dropout = nn.Dropout(rate)\n\n    def forward(self, x, training=False):\n        if self.train_counter < self.start_step:\n            output = x\n        else:\n            output = self.dropout(x) if training else x\n        if training:\n            self.train_counter += 1\n        return output\n\nclass CausalDWConv1D(nn.Module):\n    def __init__(self, channels, kernel_size=17, dilation_rate=1, use_bias=False):\n        super().__init__()\n        self.causal_pad = nn.ConstantPad1d((dilation_rate * (kernel_size - 1), 0), 0)\n        self.dw_conv = nn.Conv1d(\n            in_channels=channels,\n            out_channels=channels,\n            kernel_size=kernel_size,\n            stride=1,\n            dilation=dilation_rate,\n            padding=0,\n            groups=channels,  # This makes it truly depthwise\n            bias=use_bias\n        )\n        \n    def forward(self, x):\n        # x should be [B, C, L]\n        x = self.causal_pad(x)\n        x = self.dw_conv(x)\n        return x\n\nclass Conv1DBlock(nn.Module):\n    def __init__(self, channel_size, kernel_size, dilation_rate=1, drop_rate=0.0, expand_ratio=2, activation=F.silu):\n        super().__init__()\n        self.channel_size = channel_size\n        self.expanded_size = channel_size * expand_ratio\n        \n        # Layers\n        self.norm1 = nn.LayerNorm(channel_size)\n        self.expand_conv = nn.Linear(channel_size, self.expanded_size)\n        self.norm2 = nn.LayerNorm(self.expanded_size)\n        self.dw_conv = CausalDWConv1D(self.expanded_size, kernel_size, dilation_rate)\n        self.eca = ECA(kernel_size=5)\n        self.project_conv = nn.Linear(self.expanded_size, channel_size)\n        self.dropout = nn.Dropout(drop_rate)\n        self.activation = activation\n        \n    def forward(self, x):\n        # x is [B, L, C]\n        skip = x\n        \n        # Pre-normalization\n        x = self.norm1(x)\n        \n        # Expansion\n        x = self.expand_conv(x)  # [B, L, C*expand]\n        x = self.activation(x)\n        \n        # Depthwise conv requires channels first\n        x = x.transpose(1, 2)  # [B, C*expand, L]\n        x = self.dw_conv(x)\n        \n        # Apply ECA\n        x = self.eca(x)\n        \n        # Back to [B, L, C*expand] for projection\n        x = x.transpose(1, 2)\n        \n        # Normalization before projection\n        x = self.norm2(x)\n        \n        # Project back to original dimensionality\n        x = self.project_conv(x)  # [B, L, C]\n        x = self.dropout(x)\n        \n        # Residual connection if shapes match\n        if x.shape == skip.shape:\n            x = x + skip\n            \n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T19:28:52.777464Z","iopub.execute_input":"2025-04-11T19:28:52.777753Z","iopub.status.idle":"2025-04-11T19:28:52.789096Z","shell.execute_reply.started":"2025-04-11T19:28:52.777731Z","shell.execute_reply":"2025-04-11T19:28:52.788436Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"class CFG:\n    n_splits = 5\n    df = pd.read_csv(f\"{BASE_DIR}/train.csv\")\n    save_output = True\n    output_dir = '.'\n    \n    seed = 42\n    verbose = 2 #0) silent 1) progress bar 2) one line per epoch\n    \n    max_len = 384\n    replicas = 8\n    lr = 5e-4 * replicas\n    weight_decay = 0.1\n    lr_min = 1e-6\n    epoch = 5 #400\n    # warmup needs to be between 0 and 1\n    warmup = 0.1\n    batch_size = 64 * replicas\n    snapshot_epochs = []\n    swa_epochs = [] #list(range(epoch//2,epoch+1))\n    \n    fp16 = True\n    fgm = False\n    awp = True\n    awp_lambda = 0.2\n    awp_start_epoch = 15\n    dropout_start_epoch = 15\n    resume = 0\n    decay_type = 'cosine'\n    dim = 192\n    comment = f'islr-fp16-192-8-seed{seed}'\n    device = device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T19:28:53.709767Z","iopub.execute_input":"2025-04-11T19:28:53.710105Z","iopub.status.idle":"2025-04-11T19:28:53.802222Z","shell.execute_reply.started":"2025-04-11T19:28:53.710075Z","shell.execute_reply":"2025-04-11T19:28:53.801484Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"train_folds(CFG, [0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T19:28:54.906820Z","iopub.execute_input":"2025-04-11T19:28:54.907134Z","iopub.status.idle":"2025-04-11T20:02:36.355798Z","shell.execute_reply.started":"2025-04-11T19:28:54.907105Z","shell.execute_reply":"2025-04-11T20:02:36.354463Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()  # Updated to use GradScaler directly\n","output_type":"stream"},{"name":"stdout","text":"Number of training samples: 75581, batches: 148\nNumber of validation samples: 18896\nTraining fold 0...\nGetModel(\n  (stem_conv): Linear(in_features=708, out_features=192, bias=False)\n  (stem_bn): BatchNorm1d(384, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n  (blocks): Sequential(\n    (0): Conv1DBlock(\n      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n      (expand_conv): Linear(in_features=192, out_features=384, bias=True)\n      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dw_conv): CausalDWConv1D(\n        (causal_pad): ConstantPad1d(padding=(16, 0), value=0)\n        (dw_conv): Conv1d(384, 384, kernel_size=(17,), stride=(1,), groups=384, bias=False)\n      )\n      (eca): ECA(\n        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n        (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n        (sigmoid): Sigmoid()\n      )\n      (project_conv): Linear(in_features=384, out_features=192, bias=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (1): Conv1DBlock(\n      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n      (expand_conv): Linear(in_features=192, out_features=384, bias=True)\n      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dw_conv): CausalDWConv1D(\n        (causal_pad): ConstantPad1d(padding=(16, 0), value=0)\n        (dw_conv): Conv1d(384, 384, kernel_size=(17,), stride=(1,), groups=384, bias=False)\n      )\n      (eca): ECA(\n        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n        (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n        (sigmoid): Sigmoid()\n      )\n      (project_conv): Linear(in_features=384, out_features=192, bias=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (2): Conv1DBlock(\n      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n      (expand_conv): Linear(in_features=192, out_features=384, bias=True)\n      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dw_conv): CausalDWConv1D(\n        (causal_pad): ConstantPad1d(padding=(16, 0), value=0)\n        (dw_conv): Conv1d(384, 384, kernel_size=(17,), stride=(1,), groups=384, bias=False)\n      )\n      (eca): ECA(\n        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n        (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n        (sigmoid): Sigmoid()\n      )\n      (project_conv): Linear(in_features=384, out_features=192, bias=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (3): TransformerBlock(\n      (attn_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (attn): MultiHeadSelfAttention(\n        (qkv): Linear(in_features=192, out_features=576, bias=False)\n        (drop1): Dropout(p=0.2, inplace=False)\n        (proj): Linear(in_features=192, out_features=192, bias=False)\n      )\n      (attn_drop): Dropout(p=0.2, inplace=False)\n      (ffn_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ffn): Sequential(\n        (0): Linear(in_features=192, out_features=384, bias=False)\n        (1): SiLU()\n        (2): Linear(in_features=384, out_features=192, bias=False)\n        (3): Dropout(p=0.2, inplace=False)\n      )\n    )\n    (4): Conv1DBlock(\n      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n      (expand_conv): Linear(in_features=192, out_features=384, bias=True)\n      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dw_conv): CausalDWConv1D(\n        (causal_pad): ConstantPad1d(padding=(16, 0), value=0)\n        (dw_conv): Conv1d(384, 384, kernel_size=(17,), stride=(1,), groups=384, bias=False)\n      )\n      (eca): ECA(\n        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n        (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n        (sigmoid): Sigmoid()\n      )\n      (project_conv): Linear(in_features=384, out_features=192, bias=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (5): Conv1DBlock(\n      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n      (expand_conv): Linear(in_features=192, out_features=384, bias=True)\n      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dw_conv): CausalDWConv1D(\n        (causal_pad): ConstantPad1d(padding=(16, 0), value=0)\n        (dw_conv): Conv1d(384, 384, kernel_size=(17,), stride=(1,), groups=384, bias=False)\n      )\n      (eca): ECA(\n        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n        (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n        (sigmoid): Sigmoid()\n      )\n      (project_conv): Linear(in_features=384, out_features=192, bias=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (6): Conv1DBlock(\n      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n      (expand_conv): Linear(in_features=192, out_features=384, bias=True)\n      (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dw_conv): CausalDWConv1D(\n        (causal_pad): ConstantPad1d(padding=(16, 0), value=0)\n        (dw_conv): Conv1d(384, 384, kernel_size=(17,), stride=(1,), groups=384, bias=False)\n      )\n      (eca): ECA(\n        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n        (conv): Conv1d(1, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n        (sigmoid): Sigmoid()\n      )\n      (project_conv): Linear(in_features=384, out_features=192, bias=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (7): TransformerBlock(\n      (attn_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (attn): MultiHeadSelfAttention(\n        (qkv): Linear(in_features=192, out_features=576, bias=False)\n        (drop1): Dropout(p=0.2, inplace=False)\n        (proj): Linear(in_features=192, out_features=192, bias=False)\n      )\n      (attn_drop): Dropout(p=0.2, inplace=False)\n      (ffn_norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (ffn): Sequential(\n        (0): Linear(in_features=192, out_features=384, bias=False)\n        (1): SiLU()\n        (2): Linear(in_features=384, out_features=192, bias=False)\n        (3): Dropout(p=0.2, inplace=False)\n      )\n    )\n  )\n  (top_conv): Linear(in_features=192, out_features=384, bias=True)\n  (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n  (dropout): Dropout(p=0.8, inplace=False)\n  (classifier): Linear(in_features=384, out_features=250, bias=True)\n)\nTotal training steps: 740\nOn epoch number: 1 / 5\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([512, 250])\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-81-a6d8f428a364>:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=CFG.fp16):  # Updated to use autocast directly\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([317, 250])\nEpoch 1 took 2005.1590123176575 seconds to train\nEpoch 1/5, Loss: nan, Accuracy: 0.0044\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-84-863c794cb203>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-81-a6d8f428a364>\u001b[0m in \u001b[0;36mtrain_folds\u001b[0;34m(CFG, folds, strategy, summary)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mvalid_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-81-a6d8f428a364>\u001b[0m in \u001b[0;36mtrain_fold\u001b[0;34m(CFG, fold, train_files, valid_files, strategy, summary)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-60-8881d746ad1c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (196608x3 and 708x192)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (196608x3 and 708x192)","output_type":"error"}],"execution_count":84},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}