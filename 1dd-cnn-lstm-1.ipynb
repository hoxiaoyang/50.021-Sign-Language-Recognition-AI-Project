{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":46105,"databundleVersionId":5087314,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir('/kaggle/input/asl-signs'))\n   \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:54.979787Z","iopub.execute_input":"2025-04-14T03:22:54.980139Z","iopub.status.idle":"2025-04-14T03:22:54.985357Z","shell.execute_reply.started":"2025-04-14T03:22:54.980112Z","shell.execute_reply":"2025-04-14T03:22:54.984225Z"}},"outputs":[{"name":"stdout","text":"['sign_to_prediction_index_map.json', 'train.csv', 'train_landmark_files']\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# Kaggle already includes these; no need to install\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:54.986678Z","iopub.execute_input":"2025-04-14T03:22:54.986898Z","iopub.status.idle":"2025-04-14T03:22:54.997760Z","shell.execute_reply.started":"2025-04-14T03:22:54.986875Z","shell.execute_reply":"2025-04-14T03:22:54.997084Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"BASE_DIR = \"/kaggle/input/asl-signs\"  # or your local path\nROWS_PER_FRAME = 543\nNUM_CLASSES = 250\nMAX_LEN = 384  # Frames to keep per sample\nPAD = -100.0\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:54.998417Z","iopub.execute_input":"2025-04-14T03:22:54.998745Z","iopub.status.idle":"2025-04-14T03:22:55.009877Z","shell.execute_reply.started":"2025-04-14T03:22:54.998728Z","shell.execute_reply":"2025-04-14T03:22:55.009220Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Define landmark indices from MediaPipe\nLIP = [61, 185, 40, 39, 37, 267, 269, 270, 409, 291, 146, 91, 181, 84, 17, 314, 405, 321, 375]\nLHAND = np.arange(468, 489).tolist()\nRHAND = np.arange(522, 543).tolist()\nNOSE = [1, 2, 98, 327]\nREYE = [33, 7, 163, 144, 145]\nLEYE = [263, 249, 390, 373, 374]\n\nPOINT_LANDMARKS = LIP + LHAND + RHAND + NOSE + REYE + LEYE\nNUM_NODES = len(POINT_LANDMARKS)\nCHANNELS = 6 * NUM_NODES\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.011232Z","iopub.execute_input":"2025-04-14T03:22:55.011682Z","iopub.status.idle":"2025-04-14T03:22:55.022140Z","shell.execute_reply.started":"2025-04-14T03:22:55.011667Z","shell.execute_reply":"2025-04-14T03:22:55.021564Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"df = pd.read_csv(f\"{BASE_DIR}/train.csv\")\nle = LabelEncoder()\ndf['label'] = le.fit_transform(df['sign'])\nsign_to_index = {s: i for i, s in enumerate(le.classes_)}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.022804Z","iopub.execute_input":"2025-04-14T03:22:55.022985Z","iopub.status.idle":"2025-04-14T03:22:55.175335Z","shell.execute_reply.started":"2025-04-14T03:22:55.022971Z","shell.execute_reply":"2025-04-14T03:22:55.174491Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def torch_nan_mean(x, dim=0, keepdim=False):\n    mask = ~torch.isnan(x)\n    x = torch.where(mask, x, torch.zeros_like(x))\n    count = mask.sum(dim=dim, keepdim=keepdim).clamp(min=1)\n    return x.sum(dim=dim, keepdim=keepdim) / count\n\ndef torch_nan_std(x, center=None, dim=0, keepdim=False):\n    if center is None:\n        center = torch_nan_mean(x, dim=dim, keepdim=True)\n    d = x - center\n    variance = torch_nan_mean(d * d, dim=dim, keepdim=keepdim)\n    return torch.sqrt(variance)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.176205Z","iopub.execute_input":"2025-04-14T03:22:55.176528Z","iopub.status.idle":"2025-04-14T03:22:55.181500Z","shell.execute_reply.started":"2025-04-14T03:22:55.176506Z","shell.execute_reply":"2025-04-14T03:22:55.180825Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"class Preprocess(nn.Module):\n    def __init__(self, max_len=None, point_landmarks=None):\n        super().__init__()\n        self.max_len = max_len\n        self.point_landmarks = point_landmarks\n\n    def forward(self, inputs):\n        if inputs.dim() == 3:\n            x = inputs.unsqueeze(0)\n        else:\n            x = inputs\n\n        mean = torch_nan_mean(x[:, :, [17], :], dim=(1, 2), keepdim=True)\n\n        mean = torch.where(torch.isnan(mean), torch.tensor(0.5, device=x.device), mean)\n\n        x = x[:, :, self.point_landmarks, :]\n        std = torch_nan_std(x, mean, dim=(1, 2), keepdim=True)\n\n        x = (x - mean) / std\n\n        if self.max_len:\n            x = x[:, :self.max_len]\n        length = x.shape[1]\n\n        x = x[..., :2]  # drop z\n\n        dx = torch.cat([x[:, 1:] - x[:, :-1], torch.zeros_like(x[:, :1])], dim=1)\n        dx2 = torch.cat([x[:, 2:] - x[:, :-2], torch.zeros_like(x[:, :2])], dim=1)\n\n        x = torch.cat([\n            x.reshape(-1, length, 2 * len(self.point_landmarks)),\n            dx.reshape(-1, length, 2 * len(self.point_landmarks)),\n            dx2.reshape(-1, length, 2 * len(self.point_landmarks)),\n        ], dim=-1)\n\n        return torch.nan_to_num(x, nan=0.0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.182250Z","iopub.execute_input":"2025-04-14T03:22:55.182495Z","iopub.status.idle":"2025-04-14T03:22:55.196034Z","shell.execute_reply.started":"2025-04-14T03:22:55.182472Z","shell.execute_reply":"2025-04-14T03:22:55.195329Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"def preprocess(x, sign, max_len=MAX_LEN):\n    x = torch.tensor(x, dtype=torch.float32)\n    x = x.view(-1, ROWS_PER_FRAME, 3)\n\n    if x.shape[0] < max_len:\n        pad_len = max_len - x.shape[0]\n        pad = torch.zeros((pad_len, ROWS_PER_FRAME, 3))\n        x = torch.cat([x, pad], dim=0)\n    else:\n        x = x[:max_len]\n\n    processor = Preprocess(max_len=max_len, point_landmarks=POINT_LANDMARKS)\n    x = processor(x.unsqueeze(0)).squeeze(0)\n\n    label = sign_to_index[sign]\n    return x, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.196851Z","iopub.execute_input":"2025-04-14T03:22:55.197531Z","iopub.status.idle":"2025-04-14T03:22:55.211600Z","shell.execute_reply.started":"2025-04-14T03:22:55.197508Z","shell.execute_reply":"2025-04-14T03:22:55.210943Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"class SignLanguageDataset(Dataset):\n    def __init__(self, df, max_len=384,augment=False, transform=None):\n        self.df = df\n        self.max_len = max_len\n        self.augment = augment\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        path = os.path.join(BASE_DIR, row['path'])\n        data = pd.read_parquet(path)\n        coords = data[['x', 'y', 'z']].values\n\n        x, y = self.transform(coords, row['sign'], max_len=self.max_len)\n        return x.float(), torch.tensor(y).long()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.213312Z","iopub.execute_input":"2025-04-14T03:22:55.213511Z","iopub.status.idle":"2025-04-14T03:22:55.225400Z","shell.execute_reply.started":"2025-04-14T03:22:55.213488Z","shell.execute_reply":"2025-04-14T03:22:55.224698Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def get_pytorch_dataset(df, batch_size=64, max_len=384,augment=False, transform=None):\n    dataset = SignLanguageDataset(df, max_len=max_len, transform=transform)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2,pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.226041Z","iopub.execute_input":"2025-04-14T03:22:55.226313Z","iopub.status.idle":"2025-04-14T03:22:55.239766Z","shell.execute_reply.started":"2025-04-14T03:22:55.226296Z","shell.execute_reply":"2025-04-14T03:22:55.238855Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.1, stratify=df['sign'], random_state=42)\n\ntrain_loader = get_pytorch_dataset(train_df, batch_size=64, max_len=384, transform=preprocess)\nval_loader = get_pytorch_dataset(val_df, batch_size=64, max_len=384, transform=preprocess)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.240468Z","iopub.execute_input":"2025-04-14T03:22:55.240702Z","iopub.status.idle":"2025-04-14T03:22:55.358410Z","shell.execute_reply.started":"2025-04-14T03:22:55.240686Z","shell.execute_reply":"2025-04-14T03:22:55.357875Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"BUILD THE 1D CNN + LSTM MODEL ","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass CNNLSTMModel(nn.Module):\n    def __init__(self, input_dim=708, num_classes=250, hidden_size=256):\n        super(CNNLSTMModel, self).__init__()\n\n        self.conv1 = nn.Conv1d(input_dim, 256, kernel_size=3, padding=1)\n        self.relu1 = nn.ReLU()\n        self.bn1 = nn.BatchNorm1d(256)\n        self.dropout1 = nn.Dropout(0.3)\n\n        self.lstm = nn.LSTM(input_size=256, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n\n        self.fc1 = nn.Linear(hidden_size * 2, 256)\n        self.relu2 = nn.ReLU()\n        self.dropout2 = nn.Dropout(0.3)\n        self.fc_out = nn.Linear(256, num_classes)\n\n    def forward(self, x):  # x: (batch, seq_len, features)\n        x = x.transpose(1, 2)  # â†’ (batch, features, seq_len) for Conv1D\n        x = self.dropout1(self.bn1(self.relu1(self.conv1(x))))\n        x = x.transpose(1, 2)  # â†’ (batch, seq_len, features) for LSTM\n\n        lstm_out, _ = self.lstm(x)  # â†’ (batch, seq_len, hidden*2)\n        x = lstm_out[:, -1, :]  # Use last timestep\n\n        x = self.dropout2(self.relu2(self.fc1(x)))\n        return self.fc_out(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.359015Z","iopub.execute_input":"2025-04-14T03:22:55.359202Z","iopub.status.idle":"2025-04-14T03:22:55.365920Z","shell.execute_reply.started":"2025-04-14T03:22:55.359188Z","shell.execute_reply":"2025-04-14T03:22:55.365191Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"from sklearn.metrics import f1_score, accuracy_score\n\ndef compute_metrics(y_true, y_pred):\n    y_true = y_true.cpu().numpy()\n    y_pred = y_pred.cpu().numpy()\n\n    preds = y_pred.argmax(axis=1)\n    acc = accuracy_score(y_true, preds)\n    f1 = f1_score(y_true, preds, average='macro')\n\n    return {\n        \"accuracy\": acc,\n        \"f1_score\": f1,\n        \"score\": (acc + f1) / 2  # Final metric\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.366767Z","iopub.execute_input":"2025-04-14T03:22:55.366999Z","iopub.status.idle":"2025-04-14T03:22:55.376028Z","shell.execute_reply.started":"2025-04-14T03:22:55.366982Z","shell.execute_reply":"2025-04-14T03:22:55.375336Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\nfrom tqdm import tqdm\n\ndef train_model(model, dataloader, validloader, optimizer, criterion, epochs=10):\n    best_score = 0\n    scaler = GradScaler()  # For mixed precision\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n\n        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n        for inputs, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            with autocast():  # Mixed precision context\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            total_loss += loss.item()\n\n        print(f\"Train Loss: {total_loss / len(dataloader):.4f}\")\n\n        # ðŸ” Validation (no need for AMP here)\n        model.eval()\n        all_preds, all_labels = [], []\n        with torch.no_grad():\n            for inputs, labels in validloader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                all_preds.append(outputs.cpu())\n                all_labels.append(labels.cpu())\n\n        all_preds = torch.cat(all_preds)\n        all_labels = torch.cat(all_labels)\n\n        metrics = compute_metrics(all_labels, all_preds)\n        print(f\"Validation Accuracy: {metrics['accuracy']:.4f}, F1 Score: {metrics['f1_score']:.4f}, Combined Score: {metrics['score']:.4f}\")\n\n        if metrics['score'] > best_score:\n            best_score = metrics['score']\n            torch.save(model.state_dict(), \"best_model.pt\")\n            print(\"âœ… New best model saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:22:55.376806Z","iopub.execute_input":"2025-04-14T03:22:55.377051Z","iopub.status.idle":"2025-04-14T03:22:55.387748Z","shell.execute_reply.started":"2025-04-14T03:22:55.377030Z","shell.execute_reply":"2025-04-14T03:22:55.387149Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Load dataset\ntrain_df, val_df = train_test_split(df, test_size=0.1, stratify=df['sign'], random_state=42)\n\ntrain_loader = get_pytorch_dataset(train_df, batch_size=64, max_len=384, augment=True, transform=preprocess)\nval_loader = get_pytorch_dataset(val_df, batch_size=64, max_len=384, augment=False, transform=preprocess)\n\n# Initialize model\nmodel = CNNLSTMModel(input_dim=450, num_classes=250).to(device)\n\n# Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# Train\ntrain_model(model, train_loader, val_loader, optimizer, criterion, epochs=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T03:25:31.148215Z","iopub.execute_input":"2025-04-14T03:25:31.148506Z","iopub.status.idle":"2025-04-14T04:26:35.189012Z","shell.execute_reply.started":"2025-04-14T03:25:31.148483Z","shell.execute_reply":"2025-04-14T04:26:35.188228Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"                                                             ","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.4561\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.0093, F1 Score: 0.0011, Combined Score: 0.0052\nâœ… New best model saved!\n\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"                                                             ","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.3724\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.0123, F1 Score: 0.0023, Combined Score: 0.0073\nâœ… New best model saved!\n\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"                                                             ","output_type":"stream"},{"name":"stdout","text":"Train Loss: 5.3471\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.0130, F1 Score: 0.0033, Combined Score: 0.0081\nâœ… New best model saved!\n","output_type":"stream"}],"execution_count":51}]}